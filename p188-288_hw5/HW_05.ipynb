{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"HW_05.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnrhYaOSGTt0"
   },
   "source": [
    "## Homework 5\n",
    "\n",
    "## <em> Markov Chain Simulation and Hierarchical Model</em>\n",
    "<br>\n",
    "This notebook is arranged in cells. Texts are usually written in the markdown cells, and here you can use html tags (make it bold, italic, colored, etc). You can double click on this cell to see the formatting.<br>\n",
    "<br>\n",
    "The ellipsis (...) are provided where you are expected to write your solution but feel free to change the template (not over much) in case this style is not to your taste. <br>\n",
    "<br>\n",
    "<em>Hit \"Shift-Enter\" on a code cell to evaluate it.  Double click a Markdown cell to edit. </em><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B47XzZOGTt4"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1729660006350,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "0UpkwBPmGTt4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "#For plotting?\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWPVbxDiGTt7"
   },
   "source": [
    "#### Problem 1 - Simulated Annealing\n",
    "\n",
    "Reference: Newman, Computational Physics (p. 490-497)<br><br>\n",
    "For a physical system in equilibrium at temperature $T$, the probability that at any moment the system is in a state $i$ is given by the Boltzmann probability. Let us assume our system has single unique ground state and let us choose our energy scale so that $E_i = 0$ in the ground state and $E_i > 0$ for all other states. Now suppose we cool down the system to absolute zero. The system will definitely be in the ground state, and consequently one way to find the ground state of the system is to cool it down to $T = 0$.\n",
    "<br><br>\n",
    "This in turn suggests a computational strategy for finding the ground state: let us simulate the system at temperature $T$, using the Markov chain Monte Carlo method, then lower the temperature to zero and the system should find its way to the ground state. This same approach could be used to find the minimum of any function, not just the energy of a physical system. we can take any mathematical function $f(x, y, z, ...)$ and treat the independent variables $x, y, z$ as defining a \"state\" of the system and $f$ as being the energy of that system, then perform a Monte Carlo simulation. Taking the temperature down to zero will again cause the system to fall into its ground state, i.e. the state with the lowest value of $f$, and hence we find the minimum of the function.\n",
    "<br><br>\n",
    "However, if the system is cooled rapidly, it can get stuck in a local energy minimum. On the other hand, an annealed system, one that is cooled sufficiently slowly, can find its way to the ground state. Simulated annleaing applies the same idea in a computational setting. It mimics the slow cooling of a material on the computer by using a Monte Carlo simulation with a temperature parameter that is gradually lowered from an initially high value towards zero. The initial temperature should be chosen so that the system equilibrates quickly. To achieve this, we should choose the thermal energy to be significantly greater than the typical energy change accompanying a single Monte Carlo move.\n",
    "<br><br>\n",
    "As for the rate of cooling, one typically specifies a \"cooling schedule,\" a trajectory for the temperature as a function of time, and the most common choise is the exponential one:\n",
    "<br><br>\n",
    "$$ T = T_0 e^{-t/\\tau} $$\n",
    "<br><br>\n",
    "where $T_0$ is the initial temperature, and $\\tau$ is a time constant. Some trial error may be necessary to find a good value for $\\tau$.\n",
    "<br><br>\n",
    "As an example of the use of simulated annealing, we will look at one of the most famous optimization problems, traveling salesman problem, which involves finding the shortest route that visits a given set of locations on a map. A salesman wishes to visit $N$ given cities, and we assume that he can travel in a straight line between any pair of citiies. Given the coordinates of the cities, the problem is to devise the shortest tour. It should start and end at the same city, and all cities must be visited at least once. Let us denote the position of the city $i$ by the two-dimensional vector $r_i = (x_i, y_i)$.\n",
    "<br><br>\n",
    "Here is the solution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "executionInfo": {
     "elapsed": 17826,
     "status": "ok",
     "timestamp": 1729660032035,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "m6DHB8dFGTt9",
    "outputId": "d3748e24-9bd3-4682-e429-58bf3d886736"
   },
   "outputs": [],
   "source": [
    "# Traveling salesman (Newman p. 493)\n",
    "from math import sqrt,exp\n",
    "from numpy import empty\n",
    "from random import random,randrange\n",
    "from imageio.v2 import imread\n",
    "\n",
    "N = 25\n",
    "R = 0.02\n",
    "Tmax = 10.0\n",
    "Tmin = 1e-3\n",
    "tau = 1e4\n",
    "\n",
    "# Function to calculate the magnitude of a vector\n",
    "def mag(x):\n",
    "    return sqrt(x[0]**2+x[1]**2)\n",
    "\n",
    "# Function to calculate the total length of the tour\n",
    "def distance():\n",
    "    s = 0.0\n",
    "    for i in range(N):\n",
    "        s += mag(r[i+1]-r[i])\n",
    "    return s\n",
    "\n",
    "# Choose N city locations and calculate the initial distance\n",
    "r = empty([N+1,2],float)\n",
    "for i in range(N):\n",
    "    r[i,0] = random()\n",
    "    r[i,1] = random()\n",
    "r[N] = r[0]\n",
    "D = distance()\n",
    "\n",
    "# Main loop\n",
    "t = 0\n",
    "T = Tmax\n",
    "while T>Tmin:\n",
    "\n",
    "    # Cooling\n",
    "    t += 1\n",
    "    T = Tmax*exp(-t/tau)\n",
    "\n",
    "    # Choose two cities to swap and make sure they are distinct\n",
    "    i,j = randrange(1,N),randrange(1,N)\n",
    "    while i==j:\n",
    "        i,j = randrange(1,N),randrange(1,N)\n",
    "\n",
    "    # Swap them and calculate the change in distance\n",
    "    oldD = D\n",
    "    r[i,0],r[j,0] = r[j,0],r[i,0]\n",
    "    r[i,1],r[j,1] = r[j,1],r[i,1]\n",
    "    D = distance()\n",
    "    deltaD = D - oldD\n",
    "\n",
    "    # If the move is rejected, swap them back again\n",
    "    if random()>exp(-deltaD/T):\n",
    "        r[i,0],r[j,0] = r[j,0],r[i,0]\n",
    "        r[i,1],r[j,1] = r[j,1],r[i,1]\n",
    "        D = oldD\n",
    "\n",
    "plt.figure(figsize = (8, 7))\n",
    "img = imread(\"./map_sacramento.png\")\n",
    "plt.plot(r[:,0], r[:,1], 'o-', color = 'crimson', zorder=1)\n",
    "plt.imshow(img,zorder=0, extent=[-0.1, 1.1, -0.1, 1.1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-m41de2GTt-"
   },
   "source": [
    "Now, consider the function $f(x) = x^2 âˆ’ \\mathrm{cos}(4\\pi x)$, which looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 1350,
     "status": "ok",
     "timestamp": 1729660033378,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "cvGGe_bDGTt_",
    "outputId": "a5f6723e-401b-4e4c-aa63-87a52a593899"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 2, 100)\n",
    "y = x**2 - np.cos(4*np.pi*x)\n",
    "plt.plot(x, y)\n",
    "plt.grid(True); plt.xlim(-2, 2); plt.xlabel('$x$'); plt.ylabel('$f(x)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6i79ouRGGTt_"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Clearly the global minimum of this function is at $x = 0$.\n",
    "\n",
    "<span style=\"color:blue\"><i> 1. Write a program to confirm this fact using simulated annealing starting at, say, $x = 2$, with Monte Carlo moves of the form $x \\rightarrow x + \\delta$ where $\\delta$ is a random number drawn from a Gaussian distribution with mean zero and standard deviation one. Use an exponential cooling schedule and adjust the start and end temperatures, as well as the exponential constant, until you find values that give good answers in reasonable time. Have your program make a plot of the values of $x$ as a function of time during the run and have it print out the final value of x at the end. You will find the plot easier to interpret if you make it using dots rather than lines, with a statement of the form plot(x,\".\") or similar. </i></span> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "executionInfo": {
     "elapsed": 1394,
     "status": "ok",
     "timestamp": 1729660034770,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "5qDSa4lkGTuA",
    "outputId": "a5c1dd77-4d9d-44c1-c701-67769397281a",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "np.random.seed(rng_seed)\n",
    "...\n",
    "print('x = {} with f(x) = {}'.format(x,fx))\n",
    "\n",
    "# Now Plot:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TLscflDYGTuA"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<span style=\"color:blue\"> <i> 2. Now adapt your program to find the minimum of the more complicated function $f(x) = \\mathrm{cos}(x) + \\mathrm{cos}(\\sqrt{2}x) + \\mathrm{cos}(\\sqrt{3}x)$ in the range $0 < x < 50$. Plot the function as well along this range\n",
    "\n",
    "</i></span><br><br>\n",
    "(Hint: The correct answer is around $x = 16$, but there are also competing minima around $x = 2$ and $x = 42$ that your program might find. In real-world situations, it is often good enough to find any reasonable solution to a problem, not necessarily the absolute best, so the fact that the program sometimes settles on these other solutions is not necessarily a bad thing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "executionInfo": {
     "elapsed": 2638,
     "status": "ok",
     "timestamp": 1729660037405,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "6Ij1rCYWGTuB",
    "outputId": "e2fe4930-bc03-45b8-95ff-6500685cab93",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "np.random.seed(rng_seed)\n",
    "\n",
    "def f(x):\n",
    "    ...\n",
    "\n",
    "...\n",
    "\n",
    "# Fill in the following for the autograder:\n",
    "x = ... # your optimal x value\n",
    "fx = ... # f(x) at this value\n",
    "\n",
    "print('x = {} with f(x) = {}'.format(x, fx))\n",
    "\n",
    "\n",
    "# Your plots here:\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "voRWKlRMGTuB"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5RSstkRkGTuB"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Problem 2 - Hierarchial Normal Model\n",
    "\n",
    "Reference: Gelman et al., Bayesian Data Analysis (p. 288-290)\n",
    "\n",
    "\n",
    "![Screenshot 2024-10-17 at 3.17.22â€¯PM.png](data:image/png;base64,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)\n",
    "\n",
    "<br><br>\n",
    "Table 1. Coagulation time in seconds for blood drawn from 24 animals randomly allocated to four different diets. Different treatments have different numbers of observations because the randomization was unrestricted.<br><br>\n",
    "\n",
    "Under the hierarchical normal model, data $y_{ij}$, for $i = 1, ..., n_j$ and $j = 1, ... ,J$, are independently normally distributed within each of $J$ groups, with means $\\theta_j$ and common variance $\\sigma^2$. The data is presented in Table 1. (In this case, there are $J = 4$ groups (or 4 sets of experiments - A, B, C, and D), and for each group $j$, we have a data vector $y_j$ with the mean $\\theta_j$; $y_j = [y_{1j}, ... , y_{n_j\\ j}]$ (there have been $n_j$ observations made.) (e.g. j = 1 represents the diet A group. So $y_{i1} = [y_{11}, y_{21}, y_{31}, y_{41}] = [62, 60, 63, 59]$ with $n_1 = 4.$ <br><br>\n",
    "The total number of observations is $n = \\sum_{j=1}^J n_j$. The group means ($\\theta_j$) are assumed to follow a normal distribution with unknown mean $\\mu$ and variance $\\tau^2$, and a uniform prior distribution is assumed for $(\\mu, \\mathrm{log}\\sigma, \\tau)$, with $\\sigma > 0$ and $\\tau > 0$; equivalently, $p(\\mu, \\mathrm{log}\\sigma, \\mathrm{log}\\tau) \\propto \\tau$. <br><br>\n",
    "The joint posterior density of all the parameters is<br><br>\n",
    "$$ p(\\theta, \\mu, \\mathrm{log}\\sigma, \\mathrm{log}\\tau\\ \\vert\\ y) \\propto p(\\mu, \\mathrm{log}\\sigma, \\mathrm{log}\\tau) \\prod_{j=1}^J \\mathrm{Normal}(\\theta_j\\ \\vert\\ \\mu, \\tau^2) \\prod_{j=1}^J \\prod_{i=1}^{n_j} \\mathrm{Normal}(y_{ij}\\ \\vert\\ \\theta_j, \\sigma^2) $$\n",
    "<br><br>\n",
    "where $\\mathrm{Normal}(\\theta_j\\ \\vert\\ \\mu, \\tau^2) = \\frac{1}{\\sqrt{2\\pi \\tau^2}}\\mathrm{exp}(-\\frac{(\\theta_j-\\mu)^2}{2\\tau^2})$.\n",
    "<br><br>\n",
    "<span style=\"color:blue\"> <i> 1. Now, find the MAP (Maximum A Posteriori) solution to this (find the solution to MAP for all these parameters). In other words, find $\\theta_j, \\mu, \\sigma, \\tau$ which maximizes the likelihood. </i></span><br><br>\n",
    "(Hint: The likelihood is given as $\\prod_{j=1}^J \\mathrm{Normal}(\\theta_j\\ \\vert\\ \\mu, \\tau^2) \\prod_{j=1}^J \\prod_{i=1}^{n_j} \\mathrm{Normal}(y_{ij}\\ \\vert\\ \\theta_j, \\sigma^2)$. Take the log of the likelihood and maximize it using scipy.optimize.fmin (https://docs.scipy.org/doc/scipy-0.19.1/reference/generated/scipy.optimize.fmin.html). Note that you need to make initial guesses on the parameters in order to use fmin. Make a reasonable guess! You can use a different in-built function to maximize the likelihood function. <br>\n",
    "Caveat: \"fmin\" minimizes a given function, so you should multiply the log-likelihood by $-1$ in order to maximize it using fmin.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1729660037405,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "Zj9WchMPGTuC",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "A = np.array([62, 60, 63, 59])\n",
    "B = np.array([63, 67, 71, 64, 65, 66])\n",
    "C = np.array([68, 66, 71, 67, 68, 68])\n",
    "D = np.array([56, 62, 60, 61, 63, 64, 63, 59])\n",
    "\n",
    "data = []\n",
    "data.append(A)\n",
    "data.append(B)\n",
    "data.append(C)\n",
    "data.append(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1729660037406,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "bZEezzrzGTuC",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "def minus_log_likelihood(param, y_i1=data[0], y_i2=data[1], y_i3=data[2], y_i4=data[3]):\n",
    "    theta1, theta2, theta3, theta4, mu, sigma, tau = param\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1729660037406,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "puWfmibxGTuC",
    "outputId": "5ed3304c-7e63-482d-a599-a93b096e20de",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "p_tex = [\"theta_1\", \"theta_2\", \"theta_3\", \"theta_4\", \"mu\", \"sigma\", \"tau\"]\n",
    "...\n",
    "\n",
    "param_MAP = ...\n",
    "\n",
    "for ind in range(7):\n",
    "    print(p_tex[ind], '=', param_MAP[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "nmwwZLIjGTuD"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "You should find that the MAP solution is dependent on your initial guesses. The point is that the maximal likelihood estimator is biased, even though we have all the parameters.\n",
    "Hence, it is better to use the Monte Carlo simulation for the parameter estimation; we can also determine posterior quantiles with the Monte Carlo method. First, we will try the <b>Gibbs sampler</b>. <br><br>\n",
    "<b>Starting points:</b><br>\n",
    "In this example, we can choose overdispersed starting points for each parameter $\\theta_j$ by simply taking random points from the data $y_{ij}$ from group $j$. We obtain 10 starting points for the simulations by drawing $Î¸_j$ independently in this way for each group. We also need starting points for $\\mu$, which can be taken as the average of the starting $Î¸_j$ values. No starting values are needed for $\\tau$ or $\\sigma$ as they can be drawn as the first steps in the Gibbs sampler.<br><br>\n",
    "<b>Conditional posterior distribution of $\\sigma^2$:</b><br>\n",
    "The conditional posterior density for $\\sigma^2$ has the form corresponding to a normal variance with known mean; there are $n$ observations $y_{ij}$ with means $\\theta_j$. The conditional posterior distribution is<br>\n",
    "$$ \\sigma^2 | \\theta, \\mu, \\tau, y \\sim \\mathrm{Inv}\\mbox{-}\\chi^2(n, \\hat{\\sigma}^2) $$\n",
    "<br>\n",
    "where $$\\mathrm{Inv}\\mbox{-}\\chi^2(x|n, \\hat{\\sigma}^2) = \\mathrm{Inv\\mbox{-}gamma}\\Big(\\alpha = \\frac{n}{2}, \\beta = \\frac{n}{2}\\hat{\\sigma}^2 \\Big) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}x^{-(\\alpha+1)}\\mathrm{exp}(-\\beta/x)$$\n",
    "<br>\n",
    "$$ \\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{j=1}^J \\sum_{i=1}^{n_j} (y_{ij}-\\theta_j)^2 $$\n",
    "<br><br>\n",
    "(Hint: You can take random samples from the inverse gamma function using scipy.stats.invgamma - https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.invgamma.html. <br> invgamma.rvs(alpha, scale = beta, size=1) will take one random sample from $\\mathrm{Inv\\mbox{-}gamma}(\\alpha, \\beta)$.)\n",
    "<br><br>\n",
    "<b>Conditional posterior distribution of $\\tau^2$:</b><br>\n",
    "Conditional on $y$ and the other parameters in the model, $\\mu$ has a normal distribution determined by the $J$ values $\\theta_j$:<br>\n",
    "$$ \\tau^2 | \\theta, \\mu, \\sigma, y \\sim \\mathrm{Inv}\\mbox{-}\\chi^2(J-1, \\hat{\\tau}^2) $$\n",
    "<br>\n",
    "with $$ \\hat{\\tau}^2 = \\frac{1}{J-1} \\sum_{j=1}^J (\\theta_j - \\mu)^2. $$\n",
    "<br><br>\n",
    "<b>Conditional posterior distribution of each $\\theta_j$:</b><br>\n",
    "The factors in the joint posterior density that involve $\\theta_j$ are the $N(\\mu, \\tau^2)$ prior distribution and the normal likelihood from the data in the $j$th group, $y_{ij}$ , $i = 1, ... , n_j$ . The conditional posterior distribution of each $\\theta_j$ given the other parameters in the model is <br>\n",
    "$$ \\theta_j | \\mu, \\sigma, \\tau, y \\sim \\mathrm{Normal}(\\hat{\\theta_j}, V_{\\theta_j}) $$\n",
    "<br><br>\n",
    "where the parameters of the conditional posterior distribution depend on $\\mu, \\sigma, \\tau$ as well as $y$:\n",
    "<br><br>\n",
    "$$ \\hat{\\theta_j} = \\frac{\\frac{1}{\\tau^2}\\mu + \\frac{n_j}{\\sigma^2}(\\frac{1}{n_j}\\sum_{i=1}^{n_j} y_{ij})}{\\frac{1}{\\tau^2} + \\frac{n_j}{\\sigma^2}} $$\n",
    "<br>\n",
    "$$ V_{\\theta_j} = \\frac{1}{\\frac{1}{\\tau^2} + \\frac{n_j}{\\sigma^2}} $$\n",
    "<br><br>\n",
    "These conditional distributions are independent; thus drawing the $\\theta_j$â€™s one at a time is equivalent to drawing the vector $\\theta$ all at once from its conditional posterior distribution.\n",
    "<br><br>\n",
    "<b>Conditional posterior distribution of $\\mu$:</b><br>\n",
    "Conditional on $y$ and the other parameters in the model, $\\mu$ has a normal distribution determined by the $J$ values $\\theta_j$:<br>\n",
    "$$ \\mu | \\theta, \\sigma, \\tau, y \\sim \\mathrm{Normal}(\\hat{\\mu}, \\tau^2/J) $$\n",
    "<br>\n",
    "where $\\hat{\\mu} = \\frac{1}{J}\\sum_{j=1}^J \\theta_j$.\n",
    "\n",
    "<br><br>\n",
    "<span style=\"color:blue\"> <i> 2. Define a function which does the Gibbs sampling. Take 100 samples. Remove the first 50 sequences and store the latter half. Repeat this 10 times so that you get ten Gibbs sampler sequences, each of length 50. We have 7 parameters ($\\theta_1, ..., \\theta_4, \\mu, \\sigma, \\tau$), and for each parameter, you created 10 chains, each of length 50. </i></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 582,
     "status": "ok",
     "timestamp": 1729660038250,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "BIJ1ooEFGTuE",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm, invgamma\n",
    "from numpy.random import normal\n",
    "from random import randint\n",
    "\n",
    "def Gibbs_sampling(data):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 861,
     "status": "ok",
     "timestamp": 1729660039108,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "aPDMy3JeGTuE",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "Gibbs_posterior = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "Gibbs_posterior.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1729660039109,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "jODsIpb2qCyn",
    "outputId": "fe983105-4b4f-4873-d7f5-85918a4011b5",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "Gibbs_posterior[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1729660039109,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "zINs-yC4GTuE",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# np.shape(Gibbs_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "StFQBpZcGTuE"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<span style=\"color:blue\"> <i> 3. Estimate posterior quantiles. Find and print the 2.5%, 25%, 50%, 75%, 97.5% posterior percentiles of all parameters. </i></span><br>\n",
    "(Hint: You can use np.percentile - https://docs.scipy.org/doc/numpy-dev/reference/generated/numpy.percentile.html.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1729660039109,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "NJIpY7oIGTuF",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def Gibbs_percentile(percent):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 1369,
     "status": "ok",
     "timestamp": 1729660040476,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "qn4esTjiGTuF",
    "outputId": "0a250e0f-006c-4e21-a74c-8caef17516cd",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "QZ3nLU7jGTuF"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<span style=\"color:blue\"> <i> 4. Now, test for convergence using \"Gelman-Rubin statistic.\" For all seven parameters, compute $R$ and determine if the condition $R < 1.1$ is satisfied.  </i></span><br><br>\n",
    "For a given parameter $\\theta$, the $R$ statistic compares the variance across chains with the variance within a chain.\n",
    "<br>Given chains $J=1,\\ldots,m$, each of length $n$, <br>\n",
    "Let $B=\\frac{n}{m-1} \\sum_j \\left(\\bar{\\theta}_j - \\bar{\\theta}\\right)^2$, where $\\bar{\\theta_j}$ is the average $\\theta$ for chain $j$ and $\\bar{\\theta}$ is the global average. This is proportional to the variance of the individual-chain averages for $\\theta$.<br>\n",
    "Let $W=\\frac{1}{m}\\sum_j s_j^2$, where $s_j^2$ is the estimated variance of $\\theta$ within chain $j$. This is the average of the individual-chain variances for $\\theta$.<br>\n",
    "Let $V=\\frac{n-1}{n}W + \\frac{1}{n}B$. This is an estimate for the overall variance of $\\theta$.\n",
    "<br><br>\n",
    "Finally, $R=\\sqrt{\\frac{V}{W}}$. We'd like to see $R\\approx 1$ (e.g. $R < 1.1$ is often used). Note that this calculation can also be used to track convergence of combinations of parameters, or anything else derived from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1729660040476,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "extmTI_CGTuF",
    "outputId": "4fd9972c-fa4f-4165-dd61-07a310e09709",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "p_tex = np.array([r'$theta_1$', r'$theta_2$', r'$theta_3$', r'$theta_4$', r'$mu$', r'$tau$', r'$sigma$'])\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "# Here W and V should be 1D np arrays of shape (7,), for the paparameters in the order of p_tex as given above.\n",
    "W = ...\n",
    "V = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "EnrW824lGTuG"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Now, try the <b>Metropolis algorithm</b>.\n",
    "\n",
    "<span style=\"color:blue\"> <i> 5. Run ten parallel sequences of Metropolis algorithm simulations using the package \"emcee\" (http://dfm.io/emcee/current/). First, define the log of prior (already given to you), likelihood, and posterior (Hint: http://dfm.io/emcee/current/user/line/) </i></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1729660049176,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "GWupmBv0GTuG",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import emcee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1729660049176,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "4UKukhtDGTuG",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def log_prior(param):\n",
    "    theta1, theta2, theta3, theta4, mu, sigma, tau = param\n",
    "    if sigma > 0 and tau > 0:\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "def log_likelihood(param, data0, data1, data2, data3):\n",
    "    theta1, theta2, theta3, theta4, mu, sigma, tau = param\n",
    "    return ...\n",
    "\n",
    "def log_posterior(param, data0, data1, data2, data3):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UV6B_l7VGTuG"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<span style=\"color:blue\"> <i> 6. Now, try different number of MCMC walkers and burn-in period, and number of MCMC steps. At which point do you obtain similar results to those obtained\n",
    "using Gibbs sampling? Run the MCMC chain and estimate posterior quantiles as in Part 3. </i></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37752,
     "status": "ok",
     "timestamp": 1729660086924,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "0C-YhhGdGTuG",
    "outputId": "ada95e53-db77-4c32-dda8-2604b5a0accb",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "emcee_trace = []\n",
    "for i in range(10):\n",
    "    # Here we'll set up the computation. emcee combines multiple \"walkers\",\n",
    "    # each of which is its own MCMC chain. The number of trace results will\n",
    "    # be nwalkers * nsteps\n",
    "\n",
    "    ndim = 7  # number of parameters in the model\n",
    "    nwalkers = 50  # number of MCMC walkers\n",
    "    nburn = 500 # \"burn-in\" period to let chains stabilize\n",
    "    nsteps = 1000  # number of MCMC steps to take\n",
    "\n",
    "    # set theta near the maximum likelihood, with\n",
    "    starting_guesses = np.random.random((nwalkers, ndim))\n",
    "\n",
    "    # Here's the function call where all the work happens:\n",
    "    # we'll time it using IPython's %time magic\n",
    "\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior, args=[data[0], data[1], data[2], data[3]])\n",
    "    sampler.run_mcmc(starting_guesses, nsteps)\n",
    "    print(\"done\")\n",
    "\n",
    "    emcee_trace.append(sampler.chain[:, nburn:, :].reshape(-1, ndim).T)\n",
    "\n",
    "emcee_trace = np.array(emcee_trace)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1729660086925,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "cSuqeYxcGTuH",
    "outputId": "60abc092-2bc8-444b-94e1-91fcfa2b65c9",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "np.shape(emcee_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1729660086925,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "8yVRzyhWGTuH",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def emcee_percentile(percent):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1729660086925,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "KIMIf0oCGTuH",
    "outputId": "fc2b276b-7490-475b-ce0c-b76fd4be8ec6",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 13105,
     "status": "ok",
     "timestamp": 1729660107638,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "f6xMRXqdGTuI",
    "outputId": "f34c78ce-616d-478c-edd3-57a25ba45830",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import corner\n",
    "fig = corner.corner(emcee_trace[0, :, :].T, labels=[\"$\\\\theta_1$\", \"$\\\\theta_2$\", \"$\\\\theta_3$\", \"$\\\\theta_4$\", \"$\\mu$\", \"$\\sigma$\", \"$\\\\tau$\"], quantiles=[0.16, 0.5, 0.84], range = 0.95*np.ones(7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "sdND_khZGTuI"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<span style=\"color:blue\"> <i> 7. Test for convergence using Gelman-Rubin statistic as in Part 4. </i></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1729660107638,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "XiqWh5_BGTuI",
    "outputId": "681c903f-972a-4bc2-a48c-8e037ec136b7",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "len(emcee_trace[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "p_tex = np.array([r'$theta_1$', r'$theta_2$', r'$theta_3$', r'$theta_4$', r'$mu$', r'$tau$', r'$sigma$'])\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "# Here W and V should be 1D np arrays of shape (7,), for the paparameters in the order of p_tex as given above.\n",
    "W = ...\n",
    "V = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2L4ZPN1bGTuI"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<span style=\"color:blue\"> <i> 8. Using autocorrelation_plot from pandas (https://pandas.pydata.org/pandas-docs/stable/visualization.html#visualization-autocorrelation), plot the auto-correlation of six parameters and determine that it gets small for large lag. </i></span><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1729660107639,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "TYizaUzHGTuI",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 74516,
     "status": "ok",
     "timestamp": 1729660182146,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 420
    },
    "id": "ZZBEiGFIGTuJ",
    "outputId": "289531ad-214d-4e30-a613-97581b245532",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "p_tex = np.array([r'$\\theta_1$', r'$\\theta_2$', r'$\\theta_3$', r'$\\theta_4$', r'$\\mu$', r'$\\tau$', r'$\\sigma$'])\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "AeP7F8DUGTuJ"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Submit the zip file to Gradescope!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "p188_288_hw5",
   "tests": {
    "q1.1": {
     "name": "q1.1",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(fx, -0.999, rtol=0.02)\nnp.True_",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.2": {
     "name": "q1.2",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> solns = np.array([(15.959507768509129, -2.6125883836707233), (41.74335875566357, -2.4108110768732285), (2.1553550799019874, -2.3775212046306975)]).T\n>>> np.any(np.isclose(x, solns[0], rtol=0.01, atol=0.01))\nnp.True_",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> solns = np.array([(15.959507768509129, -2.6125883836707233), (41.74335875566357, -2.4108110768732285), (2.1553550799019874, -2.3775212046306975)]).T\n>>> np.any(np.isclose(fx, solns[1], rtol=0.01, atol=0.01))\nnp.True_",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.1": {
     "name": "q2.1",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(param_MAP[0], 61.4007, rtol=0.001)\nnp.True_",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(param_MAP[-1], 2.783, rtol=0.001)\nnp.True_",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(param_MAP[2], 67.63, rtol=0.001)\nnp.True_",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.2": {
     "name": "q2.2",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> Gibbs_posterior.shape == (10, 50, 7)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.3": {
     "name": "q2.3",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> AA = Gibbs_percentile(50)\n>>> np.isclose(AA[0], 61.3225246, rtol=0.005)\nnp.True_",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> AA = Gibbs_percentile(35)\n>>> np.isclose(AA[0], 61.3225246, rtol=0.005)\nnp.False_",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> AA = Gibbs_percentile(35)\n>>> np.isclose(AA[-1], 4.4100953, rtol=0.005)\nnp.False_",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.4": {
     "name": "q2.4",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> R = np.sqrt(V / W)\n>>> np.all(R < 1.1)\nnp.True_",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.5": {
     "name": "q2.5",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> param = [60, 67, 69, 61, 66, 2.5, 4]\n>>> np.isclose(log_likelihood(param, data[0], data[1], data[2], data[3]), -65.72518393919012, rtol=0.001)\nnp.True_",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> param = [60, 67, 69, 61, 66, 2.5, -1]\n>>> np.isfinite(log_posterior(param, data[0], data[1], data[2], data[3]))\nnp.False_",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> param = [60, 67, 69, 61, 66, -1, 2]\n>>> np.isfinite(log_posterior(param, data[0], data[1], data[2], data[3]))\nnp.False_",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.6": {
     "name": "q2.6",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> AA = emcee_percentile(50)\n>>> np.isclose(AA[0], 61.24, rtol=0.005)\nnp.True_",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> AA = emcee_percentile(35)\n>>> np.isclose(AA[0], 61.3225246, rtol=0.005)\nnp.False_",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> AA = emcee_percentile(30)\n>>> np.isclose(AA[-2], 2.28289161, rtol=0.005)\nnp.True_",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.7": {
     "name": "q2.7",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> R = np.sqrt(V / W)\n>>> np.all(R < 1.1)\nnp.True_",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
